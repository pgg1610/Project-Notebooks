{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Simple example to illustrate the utility of graph neural networks. \n",
    "\n",
    "Task: Generating embedding for a graph dataset using a Graph Convolution Neural Network (GCN) on Zachary's Karate Club Network. Categorize the members of the club \n",
    "\n",
    "Data file from: [Zachary W. (1977). An information flow model for conflict and fission in small groups. Journal of Anthropological Research, 33, 452-473](http://vlado.fmf.uni-lj.si/pub/networks/data/Ucinet/UciData.htm)\n",
    "\n",
    "This is a classic dataset to look at relationships between users and its final effect on the decision. The dataset describes the social interaction of 34 members and the communities that rise from it. The new version of the data categorizes the nodes (each member) in 4 clubs. These clubs are emerged from the connections each members has with others in the 'club'. \n",
    "\n",
    "How this useful? \n",
    "- Calculate embedding to compress the graph dataset into 2 dimensions \n",
    "- Can we predict communities of club members based on their vicinity with other members "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = {\n",
    "'font.size' : 15,\n",
    "'axes.titlesize' : 24,\n",
    "'axes.labelsize' : 15,\n",
    "'axes.labelweight' : 'bold',\n",
    "'lines.linewidth' : 3,\n",
    "'xtick.labelsize' : 12,\n",
    "'ytick.labelsize' : 12,\n",
    "}\n",
    " \n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_graph(data_, h_):\n",
    "    \n",
    "    if torch.is_tensor(h_):\n",
    "        h_ = h_.detach().cpu().numpy()\n",
    "        \n",
    "    fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "    scatter = ax.scatter(h_[:,0], h_[:,1], c=data_.y, edgecolor='k', alpha = 0.8, s=10**2, cmap=cm.Set2);\n",
    "    ax.set_xlabel('Low Dimension 1')\n",
    "    ax.set_ylabel('Low Dimension 2')\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "    handles, labels = scatter.legend_elements()\n",
    "    legend1 = ax.legend(handles, ['Class 1','Class 2', 'Class 3', 'Class 4'], loc=\"best\", title=\"Classes\")\n",
    "    ax.add_artist(legend1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import KarateClub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import KarateClub\n",
    "\n",
    "dataset = KarateClub()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print(data)\n",
    "print('==============================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualizing the edge information using the `edge_function` attribute in the `data` object. This attribute stores connections for each node in a coordinate format rather than an adjacency matrix, this way the represntation is sparse, only non-zero connections are included in the object  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = data.edge_index\n",
    "print(edge_index.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "G = to_networkx(data, to_undirected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "club_officer = []\n",
    "fig, ax = plt.subplots(1,2,figsize=(20,10))\n",
    "nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), node_size=10**3, with_labels=True, node_color=data.y, cmap=\"Set2\", ax=ax[0])\n",
    "nx.draw_networkx(G, pos=nx.circular_layout(G), node_size=10**3, with_labels=True, node_color=data.y, cmap=\"Set2\", ax=ax[1])\n",
    "\n",
    "#handles, labels = ax[0].legend_elements()\n",
    "#legend1 = ax[0].legend(handles, ['Class 1','Class 2', 'Class 3', 'Class 4'], loc=\"best\", title=\"Classes\")\n",
    "#ax.add_artist(legend1);\n",
    "#ax[0].legend()\n",
    "ax[0].set_title('Spring Layout')\n",
    "ax[1].set_title('Circular Layout');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each node in the graph is a person. Every person has an associated number (index) and the club they would eventually join. In this form of visualization - node 0 and node 33 are Mr. Hi and Officer respectively. Besides that, each node has an associated edges with other nodes in the network based on connections (how exactly are those determined is not clear at first). Now having that connection we can construct an adjacency matrix. The environment of each node can be used to predict the final community the user would end up in. \n",
    "\n",
    "We can re-express this problem as given the nodes and the connections which club would each node join. We can see if the GCN network can predict the targets properly or rather if the targets can be used to find low dimensional embeddings for the graph objects such that each node is expressed in 2D. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each member of the community is described with a simple one-hot vector which in this case is a unitary matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_classes = data.y.numpy()\n",
    "unique, counts = np.unique(target_classes, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "fig, ax = plt.subplots(1,1, figsize=(9,4))\n",
    "ax.bar(unique, counts, tick_label=['Class 1','Class 2', 'Class 3', 'Class 4'], color=cm.Set2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To describe each members in the network a one-hot encoding is used where the entry corresponding to the index of the node is 1 and everything else is 0. Sorting these nodes based on index we get a identity matrix (34, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, every node in the graph is attached to other nodes. This information is stored in adjacency matrix. Self-connections are by default labelled 0. Every row of the adjacency matrix shows node connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Karate_adjacency = torch.Tensor(nx.to_numpy_matrix(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Karate_adjacency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example: as shown figure at the top if we look at node (16) it is connected to node (5,6) only. Hence in the adjacency matrix those index are 1 other that all other entries are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where( Karate_adjacency[16] == 1 )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(nn.Module):\n",
    "    def __init__(self, A, input_dims, output_dims):\n",
    "        super(GCNConv, self).__init__()\n",
    "        '''\n",
    "        As per Tipf explanation: \n",
    "        https://tkipf.github.io/graph-convolutional-networks/\n",
    "        https://arxiv.org/abs/1609.02907\n",
    "        \n",
    "        PARAMETERS: \n",
    "        ---------------\n",
    "        A: numpy.array, Adjacency matrix for the graph object \n",
    "        input_dims: int, Input dimensions for the NN params\n",
    "        output_dims: int, Output dimensions for the NN params \n",
    "        \n",
    "        RETURNS: \n",
    "        ---------------\n",
    "        out: torch.Tensor, N x output for the NN prediction\n",
    "        '''\n",
    "        torch.manual_seed(42)\n",
    "        \n",
    "        self.A_hat = A + torch.eye(A.size(0))\n",
    "        self.D     = torch.diag(torch.sum(A,1)) #Diagonal node-degree matrix \n",
    "        self.D     = self.D.inverse().sqrt()\n",
    "        self.A_hat = torch.mm( torch.mm(self.D, self.A_hat), self.D )\n",
    "        self.W     = nn.Parameter(torch.rand(input_dims, output_dims, requires_grad=True))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        out = torch.tanh(torch.mm( torch.mm(self.A_hat, X), self.W ))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, A, nfeat, nhid, c):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(A, nfeat, nhid)\n",
    "        self.conv2 = GCNConv(A, nhid, nhid)\n",
    "        self.conv3 = GCNConv(A, nhid, 2)\n",
    "        self.linear = nn.Linear(2, nhid)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        H0  = self.conv1(X)\n",
    "        H1 = self.conv2(H0)\n",
    "        H2 = self.conv3(H1)\n",
    "        out = self.linear(H2)\n",
    "        \n",
    "        return H2, out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Input vector for representing each node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_GCN = Net(Karate_adjacency, node_features.size(0), 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam( simple_GCN.parameters(), lr=0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, out = simple_GCN(node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=criterion( out[data.train_mask], data.y[data.train_mask] )\n",
    "#loss=criterion( out, data.y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, _ = simple_GCN(node_features)\n",
    "visualize_graph(data, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embeddings from the randomized initialization do not correspond to any clustering -- the red and grey points belong to 2 classes used in the dataset. Every node is condensed in two 2 dimensions here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Training the network to find low dimensional embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5000):\n",
    "    e, out = simple_GCN(node_features)\n",
    "    optimizer.zero_grad()\n",
    "    loss=criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    #loss=criterion(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 1000==0:\n",
    "        print(\"Step: {} Cross Entropy Loss = {}\".format(i, loss.item()))\n",
    "        output_, _ = simple_GCN(node_features)\n",
    "        visualize_graph(data, output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_, _ = simple_GCN(node_features)\n",
    "visualize_graph(data, output_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low dimensional embeddings learned from the target properties of the node are able to cluster into. Now this is useful as we can condense the high-dimensional graph network into 2D and label them as per the target and see the clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Using PyTorch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import add_self_loops, degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, graph_data):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.graph_data = graph_data\n",
    "        self.conv1 = GCNConv(self.graph_data.num_features, 4)\n",
    "        self.conv2 = GCNConv(4, 4)\n",
    "        self.conv3 = GCNConv(4, 2)\n",
    "        self.classifier = nn.Linear(2, self.graph_data.num_classes)\n",
    "\n",
    "    def forward(self, node_features, edge_index):\n",
    "        h = self.conv1(node_features, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.tanh()  # Final GNN embedding space.\n",
    "        \n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(dataset)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, h = model(node_features, data.edge_index)\n",
    "h = h.detach().numpy()\n",
    "print(f'Embedding shape: {list(h.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyg_output_, _ = model(node_features, data.edge_index)\n",
    "visualize_graph(data, pyg_output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Define optimizer.\n",
    "\n",
    "def train(data):\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out, h = model(node_features, data.edge_index)  # Perform a single forward pass.\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss, h\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss, h = train(data)\n",
    "    #if epoch % 10 == 0:\n",
    "    #    visualize(h, color=data.y, epoch=epoch, loss=loss)\n",
    "    #    time.sleep(0.3)\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Step: {} Cross Entropy Loss = {}\".format(epoch, loss.item()))\n",
    "        visualize_graph(data, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
